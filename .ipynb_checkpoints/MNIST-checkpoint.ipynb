{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'raise', 'invalid': 'raise', 'over': 'raise', 'under': 'raise'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.241714719086842\n"
     ]
    }
   ],
   "source": [
    "m = X_train.shape[0]\n",
    "k = 10\n",
    "L = (k - 1) / (k * m) * np.linalg.norm(X_train) #+ 10 * 2.89\n",
    "print(1/L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(784,), name='dense'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.9371 - acc: 0.9381 - val_loss: 1.1624 - val_acc: 0.9239\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9291 - acc: 0.9385 - val_loss: 1.1593 - val_acc: 0.9242\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.9222 - acc: 0.9390 - val_loss: 1.1562 - val_acc: 0.9248\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9160 - acc: 0.9395 - val_loss: 1.1528 - val_acc: 0.9248\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9105 - acc: 0.9399 - val_loss: 1.1495 - val_acc: 0.9251\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.9061 - acc: 0.9404 - val_loss: 1.1474 - val_acc: 0.9252\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.9026 - acc: 0.9406 - val_loss: 1.1454 - val_acc: 0.9252\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8995 - acc: 0.9408 - val_loss: 1.1434 - val_acc: 0.9253\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8969 - acc: 0.9410 - val_loss: 1.1414 - val_acc: 0.9250\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8945 - acc: 0.9413 - val_loss: 1.1399 - val_acc: 0.9248\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8922 - acc: 0.9415 - val_loss: 1.1383 - val_acc: 0.9250\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8898 - acc: 0.9418 - val_loss: 1.1369 - val_acc: 0.9251\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.8876 - acc: 0.9420 - val_loss: 1.1358 - val_acc: 0.9253\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.8855 - acc: 0.9421 - val_loss: 1.1348 - val_acc: 0.9254\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8832 - acc: 0.9423 - val_loss: 1.1337 - val_acc: 0.9255\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8812 - acc: 0.9425 - val_loss: 1.1329 - val_acc: 0.9255\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8793 - acc: 0.9427 - val_loss: 1.1325 - val_acc: 0.9254\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.8775 - acc: 0.9428 - val_loss: 1.1319 - val_acc: 0.9256\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8760 - acc: 0.9430 - val_loss: 1.1316 - val_acc: 0.9258\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.8747 - acc: 0.9432 - val_loss: 1.1312 - val_acc: 0.9259\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    epochs=20, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, Y_test), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.vstack((model.get_weights()[1], model.get_weights()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.890353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6509.3267"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 10.241714719086842\n"
     ]
    }
   ],
   "source": [
    "print('Learning rate =', 1/L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1/L)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 1.0459 - acc: 0.9302 - val_loss: 1.1822 - val_acc: 0.9216\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.0372 - acc: 0.9310 - val_loss: 1.1505 - val_acc: 0.9241\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 1.0212 - acc: 0.9321 - val_loss: 1.2248 - val_acc: 0.9190\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 1.0104 - acc: 0.9324 - val_loss: 1.1921 - val_acc: 0.9209\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 1.0288 - acc: 0.9315 - val_loss: 1.1771 - val_acc: 0.9229\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.0159 - acc: 0.9324 - val_loss: 1.1514 - val_acc: 0.9236\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 1.0015 - acc: 0.9335 - val_loss: 1.1470 - val_acc: 0.9244\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 1.0041 - acc: 0.9334 - val_loss: 1.1690 - val_acc: 0.9225\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 1.0057 - acc: 0.9328 - val_loss: 1.1818 - val_acc: 0.9226\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.9970 - acc: 0.9337 - val_loss: 1.1579 - val_acc: 0.9234\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.9924 - acc: 0.9346 - val_loss: 1.1711 - val_acc: 0.9224\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9859 - acc: 0.9346 - val_loss: 1.1638 - val_acc: 0.9223\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9853 - acc: 0.9344 - val_loss: 1.1924 - val_acc: 0.9218\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9768 - acc: 0.9353 - val_loss: 1.1815 - val_acc: 0.9223\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.9891 - acc: 0.9343 - val_loss: 1.1437 - val_acc: 0.9248\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9556 - acc: 0.9367 - val_loss: 1.1468 - val_acc: 0.9259\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.9547 - acc: 0.9366 - val_loss: 1.1529 - val_acc: 0.9248\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.9515 - acc: 0.9371 - val_loss: 1.1521 - val_acc: 0.9237\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.9511 - acc: 0.9369 - val_loss: 1.1574 - val_acc: 0.9233\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9593 - acc: 0.9364 - val_loss: 1.1668 - val_acc: 0.9233\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    epochs=20, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_test, Y_test), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
